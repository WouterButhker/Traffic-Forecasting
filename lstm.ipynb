{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T15:24:21.132804Z",
     "start_time": "2023-06-09T15:24:21.093543600Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import typing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.losses import MeanSquaredError\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T15:24:21.132804Z",
     "start_time": "2023-06-09T15:24:21.096545900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K120.csv', 'K140.csv', 'K159.csv', 'K405.csv', 'K406.csv', 'K701.csv', 'K703.csv', 'K709.csv']\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = 'data_cars/'\n",
    "# all_files = os.listdir(DATA_PATH)\n",
    "all_files = ['K120.csv', 'K140.csv', 'K159.csv', 'K405.csv', 'K406.csv', 'K701.csv', 'K703.csv', 'K709.csv']\n",
    "print(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T15:24:21.257764900Z",
     "start_time": "2023-06-09T15:24:21.110645500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: K120.csv\n",
      "Reading file: K140.csv\n",
      "Reading file: K159.csv\n",
      "Reading file: K405.csv\n",
      "Reading file: K406.csv\n",
      "Reading file: K701.csv\n",
      "Reading file: K703.csv\n",
      "Reading file: K709.csv\n",
      "                     K120_022  K120_023  K120_051  K120_081  K120_111   \n",
      "date                                                                    \n",
      "2019-11-01 00:00:00       3.0       3.0       9.0       5.0      19.0  \\\n",
      "2019-11-01 00:15:00       4.0       5.0       6.0       6.0      10.0   \n",
      "2019-11-01 00:30:00       0.0       3.0       1.0       2.0      15.0   \n",
      "2019-11-01 00:45:00       0.0       4.0       5.0       4.0       6.0   \n",
      "2019-11-01 01:00:00       1.0       1.0       2.0       6.0      13.0   \n",
      "...                       ...       ...       ...       ...       ...   \n",
      "2019-11-30 22:45:00       6.0       9.0      27.0      15.0      60.0   \n",
      "2019-11-30 23:00:00      12.0      11.0      27.0       8.0      49.0   \n",
      "2019-11-30 23:15:00       4.0       6.0      21.0       6.0      57.0   \n",
      "2019-11-30 23:30:00       8.0       6.0      13.0      11.0      34.0   \n",
      "2019-11-30 23:45:00       3.0       9.0      18.0       8.0      43.0   \n",
      "\n",
      "                     K120_112  K120_113  K140_031  K140_041  K140_051  ...   \n",
      "date                                                                   ...   \n",
      "2019-11-01 00:00:00       9.0       2.0       7.0       4.0       6.0  ...  \\\n",
      "2019-11-01 00:15:00       6.0       7.0       2.0       7.0       5.0  ...   \n",
      "2019-11-01 00:30:00       7.0       4.0       1.0       6.0       4.0  ...   \n",
      "2019-11-01 00:45:00       4.0       3.0       1.0       3.0       2.0  ...   \n",
      "2019-11-01 01:00:00       7.0       1.0       3.0       2.0       3.0  ...   \n",
      "...                       ...       ...       ...       ...       ...  ...   \n",
      "2019-11-30 22:45:00      29.0      19.0       4.0      20.0      14.0  ...   \n",
      "2019-11-30 23:00:00      25.0      29.0       2.0      13.0      12.0  ...   \n",
      "2019-11-30 23:15:00      22.0      21.0       3.0      12.0      12.0  ...   \n",
      "2019-11-30 23:30:00      14.0      12.0       9.0      10.0      10.0  ...   \n",
      "2019-11-30 23:45:00      16.0      15.0       7.0      12.0       6.0  ...   \n",
      "\n",
      "                     K709_11_1  K709_11_2  K709_12_1  K709_65_1  K709_65_2   \n",
      "date                                                                         \n",
      "2019-11-01 00:00:00       45.0       18.0        0.0       25.0        5.0  \\\n",
      "2019-11-01 00:15:00       30.0        8.0        0.0       13.0        2.0   \n",
      "2019-11-01 00:30:00       13.0        4.0        0.0       13.0        5.0   \n",
      "2019-11-01 00:45:00       19.0        2.0        0.0        9.0        2.0   \n",
      "2019-11-01 01:00:00       11.0        1.0        0.0        6.0        3.0   \n",
      "...                        ...        ...        ...        ...        ...   \n",
      "2019-11-30 22:45:00       74.0       30.0        1.0      124.0       75.0   \n",
      "2019-11-30 23:00:00       67.0       29.0        0.0       75.0       21.0   \n",
      "2019-11-30 23:15:00       75.0       37.0        1.0       64.0       25.0   \n",
      "2019-11-30 23:30:00       71.0       28.0        0.0       48.0       21.0   \n",
      "2019-11-30 23:45:00       63.0       23.0        0.0       48.0       12.0   \n",
      "\n",
      "                     K709_66_1  K709_71_1  K709_71_2  hour  day_of_week  \n",
      "date                                                                     \n",
      "2019-11-01 00:00:00        1.0       43.0       18.0     0            4  \n",
      "2019-11-01 00:15:00        0.0       29.0        7.0     0            4  \n",
      "2019-11-01 00:30:00        1.0       12.0        4.0     0            4  \n",
      "2019-11-01 00:45:00        1.0       18.0        2.0     0            4  \n",
      "2019-11-01 01:00:00        2.0       11.0        1.0     1            4  \n",
      "...                        ...        ...        ...   ...          ...  \n",
      "2019-11-30 22:45:00        0.0       72.0       31.0    22            5  \n",
      "2019-11-30 23:00:00        0.0       67.0       29.0    23            5  \n",
      "2019-11-30 23:15:00        1.0       72.0       37.0    23            5  \n",
      "2019-11-30 23:30:00        2.0       71.0       30.0    23            5  \n",
      "2019-11-30 23:45:00        0.0       59.0       23.0    23            5  \n",
      "\n",
      "[2880 rows x 86 columns]\n",
      "86\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "all_dataframes = []\n",
    "for index, file in enumerate(all_files):\n",
    "    print(f\"Reading file: {file}\")\n",
    "    file_name = file.split('.')[0]\n",
    "    df = pd.read_csv(DATA_PATH + file, sep=';')\n",
    "\n",
    "    df['date'] = pd.to_datetime(df[file_name], format='%Y-%m-%d %H:%M')\n",
    "    df = df.drop(columns=[file_name])\n",
    "\n",
    "    df = df.set_index('date')\n",
    "    df.columns = [f\"{file_name}_{col}\" for col in df.columns if col != 'date']\n",
    "    all_dataframes.append(df)\n",
    "    # print(f\"Finished reading file: {file}, shape = {df.shape}\")\n",
    "\n",
    "combined_df = pd.concat(all_dataframes, axis=1)\n",
    "# combined_df.fillna(method='ffill', inplace=True)\n",
    "combined_df.interpolate(method='linear', inplace=True, limit=3)\n",
    "combined_df['hour'] = combined_df.index.hour\n",
    "combined_df['day_of_week'] = combined_df.index.dayofweek\n",
    "\n",
    "# combined_df = combined_df[:]\n",
    "print(combined_df)\n",
    "print(combined_df.columns.size)\n",
    "print(combined_df.isnull().sum().sum())\n",
    "\n",
    "data = np.array(combined_df, dtype=float)[:, :]\n",
    "# data = data[:,2]\n",
    "scaler = StandardScaler()\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#Don't transform the time labels -> this way the scaler also works inversely on prediction data because shapes are different otherwise\n",
    "data = scaler.fit_transform(data)\n",
    "# data = scaler.fit_transform(data.reshape(-1, 1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T15:24:21.277272400Z",
     "start_time": "2023-06-09T15:24:21.261234700Z"
    }
   },
   "outputs": [],
   "source": [
    "timestamps = combined_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T15:24:21.316490500Z",
     "start_time": "2023-06-09T15:24:21.278305700Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = combined_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T15:24:21.323456600Z",
     "start_time": "2023-06-09T15:24:21.295492800Z"
    }
   },
   "outputs": [],
   "source": [
    "def splitSequence(seq, n_steps):\n",
    "\n",
    "    #Declare X and y as empty list\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(seq)):\n",
    "        #get the last index\n",
    "        lastIndex = i + n_steps\n",
    "\n",
    "        #if lastIndex is greater than length of sequence then break\n",
    "        if lastIndex > len(seq) - 1:\n",
    "            break\n",
    "\n",
    "        # Create input and output sequence\n",
    "        # Last 2 columns are time of day and day of week\n",
    "        seq_X, seq_y = seq[i:lastIndex], seq[lastIndex]\n",
    "\n",
    "        #append seq_X, seq_y in X and y list\n",
    "        X.append(seq_X)\n",
    "        y.append(seq_y)\n",
    "        #Convert X and y into numpy array\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T15:24:21.394048Z",
     "start_time": "2023-06-09T15:24:21.308523700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1728, 80, 1)\n",
      "(432, 80, 1)\n",
      "(640, 80, 1)\n"
     ]
    }
   ],
   "source": [
    "num_of_steps = data.shape[0]\n",
    "train_size = 0.6\n",
    "val_size = 0.15\n",
    "shuffle = True\n",
    "look_back = 80\n",
    "\n",
    "num_train = int(num_of_steps * train_size)\n",
    "num_val = int(num_of_steps * val_size)\n",
    "\n",
    "# train = data[:num_train]\n",
    "# val = data[num_train:num_train + num_val]\n",
    "# test = data[num_train + num_val:]\n",
    "\n",
    "x, y = splitSequence(data, look_back)\n",
    "\n",
    "if shuffle:\n",
    "    idx = np.random.permutation(len(x))\n",
    "    x,y = x[idx], y[idx]\n",
    "\n",
    "\n",
    "\n",
    "x_train, y_train = x[:num_train], y[:num_train]\n",
    "x_val, y_val = x[num_train:num_train + num_val], y[num_train:num_train + num_val]\n",
    "x_test, y_test = x[num_train + num_val:], y[num_train + num_val:]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "outputs": [],
   "source": [
    "removeData = False\n",
    "removeAmount = 0.6\n",
    "\n",
    "if removeData:\n",
    "    print(x_train.shape)\n",
    "    print(y_train.shape)\n",
    "\n",
    "    print(x_train[0][0])\n",
    "    #Replace random values by 0\n",
    "    for i in range(int(x_train.shape[0] * removeAmount)):\n",
    "        x_train[i] = np.zeros(x_train[i].shape)\n",
    "        y_train[i] = np.zeros(y_train[i].shape)\n",
    "        # print(x_train[i].shape)\n",
    "\n",
    "    print(x_train[0][0])\n",
    "\n",
    "    if shuffle:\n",
    "        idx = np.random.permutation(len(x))\n",
    "        x,y = x[idx], y[idx]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T15:24:21.394048Z",
     "start_time": "2023-06-09T15:24:21.356237400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T15:28:02.305051900Z",
     "start_time": "2023-06-09T15:24:21.384374200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_58\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_59 (InputLayer)       [(None, 80, 1)]           0         \n",
      "                                                                 \n",
      " lstm_116 (LSTM)             (None, 80, 60)            14880     \n",
      "                                                                 \n",
      " lstm_117 (LSTM)             (None, 60)                29040     \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 1)                 61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,981\n",
      "Trainable params: 43,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "54/54 [==============================] - 4s 29ms/step - loss: 0.4417 - root_mean_squared_error: 0.6646 - val_loss: 0.4448 - val_root_mean_squared_error: 0.6669\n",
      "Epoch 2/500\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.3152 - root_mean_squared_error: 0.5614 - val_loss: 0.3916 - val_root_mean_squared_error: 0.6258\n",
      "Epoch 3/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.3018 - root_mean_squared_error: 0.5494 - val_loss: 0.3811 - val_root_mean_squared_error: 0.6174\n",
      "Epoch 4/500\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.2864 - root_mean_squared_error: 0.5351 - val_loss: 0.3476 - val_root_mean_squared_error: 0.5896\n",
      "Epoch 5/500\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.2779 - root_mean_squared_error: 0.5271 - val_loss: 0.3763 - val_root_mean_squared_error: 0.6135\n",
      "Epoch 6/500\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.2762 - root_mean_squared_error: 0.5255 - val_loss: 0.3378 - val_root_mean_squared_error: 0.5812\n",
      "Epoch 7/500\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.2694 - root_mean_squared_error: 0.5191 - val_loss: 0.3383 - val_root_mean_squared_error: 0.5817\n",
      "Epoch 8/500\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.2752 - root_mean_squared_error: 0.5246 - val_loss: 0.3397 - val_root_mean_squared_error: 0.5829\n",
      "Epoch 9/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2634 - root_mean_squared_error: 0.5132 - val_loss: 0.3246 - val_root_mean_squared_error: 0.5697\n",
      "Epoch 10/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2627 - root_mean_squared_error: 0.5126 - val_loss: 0.3528 - val_root_mean_squared_error: 0.5939\n",
      "Epoch 11/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2589 - root_mean_squared_error: 0.5088 - val_loss: 0.3103 - val_root_mean_squared_error: 0.5571\n",
      "Epoch 12/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2587 - root_mean_squared_error: 0.5086 - val_loss: 0.3117 - val_root_mean_squared_error: 0.5583\n",
      "Epoch 13/500\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.2497 - root_mean_squared_error: 0.4997 - val_loss: 0.3158 - val_root_mean_squared_error: 0.5619\n",
      "Epoch 14/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2523 - root_mean_squared_error: 0.5023 - val_loss: 0.3291 - val_root_mean_squared_error: 0.5737\n",
      "Epoch 15/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2463 - root_mean_squared_error: 0.4963 - val_loss: 0.3173 - val_root_mean_squared_error: 0.5633\n",
      "Epoch 16/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2442 - root_mean_squared_error: 0.4942 - val_loss: 0.3045 - val_root_mean_squared_error: 0.5518\n",
      "Epoch 17/500\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.2503 - root_mean_squared_error: 0.5003 - val_loss: 0.3179 - val_root_mean_squared_error: 0.5638\n",
      "Epoch 18/500\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.2415 - root_mean_squared_error: 0.4914 - val_loss: 0.3064 - val_root_mean_squared_error: 0.5535\n",
      "Epoch 19/500\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.2509 - root_mean_squared_error: 0.5009 - val_loss: 0.3442 - val_root_mean_squared_error: 0.5867\n",
      "Epoch 20/500\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.2436 - root_mean_squared_error: 0.4936 - val_loss: 0.3234 - val_root_mean_squared_error: 0.5686\n",
      "Epoch 21/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2422 - root_mean_squared_error: 0.4921 - val_loss: 0.2937 - val_root_mean_squared_error: 0.5419\n",
      "Epoch 22/500\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.2432 - root_mean_squared_error: 0.4931 - val_loss: 0.3281 - val_root_mean_squared_error: 0.5728\n",
      "Epoch 23/500\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.2440 - root_mean_squared_error: 0.4940 - val_loss: 0.2983 - val_root_mean_squared_error: 0.5462\n",
      "Epoch 24/500\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.2386 - root_mean_squared_error: 0.4885 - val_loss: 0.3143 - val_root_mean_squared_error: 0.5606\n",
      "Epoch 25/500\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.2384 - root_mean_squared_error: 0.4883 - val_loss: 0.2932 - val_root_mean_squared_error: 0.5414\n",
      "Epoch 26/500\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.2365 - root_mean_squared_error: 0.4863 - val_loss: 0.3284 - val_root_mean_squared_error: 0.5730\n",
      "Epoch 27/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2434 - root_mean_squared_error: 0.4934 - val_loss: 0.3066 - val_root_mean_squared_error: 0.5537\n",
      "Epoch 28/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2362 - root_mean_squared_error: 0.4860 - val_loss: 0.3029 - val_root_mean_squared_error: 0.5504\n",
      "Epoch 29/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2383 - root_mean_squared_error: 0.4881 - val_loss: 0.2936 - val_root_mean_squared_error: 0.5419\n",
      "Epoch 30/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2396 - root_mean_squared_error: 0.4895 - val_loss: 0.3167 - val_root_mean_squared_error: 0.5628\n",
      "54/54 [==============================] - 2s 5ms/step\n",
      "20/20 [==============================] - 0s 5ms/step\n",
      "Train Score: 5.75 RMSE\n",
      "Test Score: 6.46 RMSE\n",
      "Model: \"model_59\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_60 (InputLayer)       [(None, 80, 1)]           0         \n",
      "                                                                 \n",
      " lstm_118 (LSTM)             (None, 80, 60)            14880     \n",
      "                                                                 \n",
      " lstm_119 (LSTM)             (None, 60)                29040     \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 1)                 61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,981\n",
      "Trainable params: 43,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "54/54 [==============================] - 4s 27ms/step - loss: 0.4300 - root_mean_squared_error: 0.6557 - val_loss: 0.4579 - val_root_mean_squared_error: 0.6767\n",
      "Epoch 2/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.3220 - root_mean_squared_error: 0.5674 - val_loss: 0.4034 - val_root_mean_squared_error: 0.6351\n",
      "Epoch 3/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.3037 - root_mean_squared_error: 0.5510 - val_loss: 0.3748 - val_root_mean_squared_error: 0.6122\n",
      "Epoch 4/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2876 - root_mean_squared_error: 0.5363 - val_loss: 0.3756 - val_root_mean_squared_error: 0.6129\n",
      "Epoch 5/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2807 - root_mean_squared_error: 0.5298 - val_loss: 0.3350 - val_root_mean_squared_error: 0.5788\n",
      "Epoch 6/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2687 - root_mean_squared_error: 0.5184 - val_loss: 0.3395 - val_root_mean_squared_error: 0.5826\n",
      "Epoch 7/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2674 - root_mean_squared_error: 0.5171 - val_loss: 0.3447 - val_root_mean_squared_error: 0.5871\n",
      "Epoch 8/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2782 - root_mean_squared_error: 0.5274 - val_loss: 0.3389 - val_root_mean_squared_error: 0.5822\n",
      "Epoch 9/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2688 - root_mean_squared_error: 0.5184 - val_loss: 0.3276 - val_root_mean_squared_error: 0.5723\n",
      "Epoch 10/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2586 - root_mean_squared_error: 0.5085 - val_loss: 0.3188 - val_root_mean_squared_error: 0.5646\n",
      "Epoch 11/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2619 - root_mean_squared_error: 0.5118 - val_loss: 0.3117 - val_root_mean_squared_error: 0.5583\n",
      "Epoch 12/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2535 - root_mean_squared_error: 0.5035 - val_loss: 0.3279 - val_root_mean_squared_error: 0.5726\n",
      "Epoch 13/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2618 - root_mean_squared_error: 0.5117 - val_loss: 0.3409 - val_root_mean_squared_error: 0.5839\n",
      "Epoch 14/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2531 - root_mean_squared_error: 0.5030 - val_loss: 0.3258 - val_root_mean_squared_error: 0.5708\n",
      "Epoch 15/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2556 - root_mean_squared_error: 0.5055 - val_loss: 0.3176 - val_root_mean_squared_error: 0.5636\n",
      "Epoch 16/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2490 - root_mean_squared_error: 0.4990 - val_loss: 0.3093 - val_root_mean_squared_error: 0.5561\n",
      "Epoch 17/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2473 - root_mean_squared_error: 0.4973 - val_loss: 0.3084 - val_root_mean_squared_error: 0.5553\n",
      "Epoch 18/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2523 - root_mean_squared_error: 0.5023 - val_loss: 0.3235 - val_root_mean_squared_error: 0.5688\n",
      "Epoch 19/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2501 - root_mean_squared_error: 0.5001 - val_loss: 0.3432 - val_root_mean_squared_error: 0.5858\n",
      "Epoch 20/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2489 - root_mean_squared_error: 0.4989 - val_loss: 0.3145 - val_root_mean_squared_error: 0.5608\n",
      "Epoch 21/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2469 - root_mean_squared_error: 0.4969 - val_loss: 0.3398 - val_root_mean_squared_error: 0.5829\n",
      "Epoch 22/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2439 - root_mean_squared_error: 0.4938 - val_loss: 0.3094 - val_root_mean_squared_error: 0.5562\n",
      "54/54 [==============================] - 1s 5ms/step\n",
      "20/20 [==============================] - 0s 5ms/step\n",
      "Train Score: 5.82 RMSE\n",
      "Test Score: 6.57 RMSE\n",
      "Model: \"model_60\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_61 (InputLayer)       [(None, 80, 1)]           0         \n",
      "                                                                 \n",
      " lstm_120 (LSTM)             (None, 80, 60)            14880     \n",
      "                                                                 \n",
      " lstm_121 (LSTM)             (None, 60)                29040     \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 1)                 61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,981\n",
      "Trainable params: 43,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "54/54 [==============================] - 3s 26ms/step - loss: 0.4241 - root_mean_squared_error: 0.6512 - val_loss: 0.4317 - val_root_mean_squared_error: 0.6570\n",
      "Epoch 2/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.3184 - root_mean_squared_error: 0.5643 - val_loss: 0.3964 - val_root_mean_squared_error: 0.6296\n",
      "Epoch 3/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.3007 - root_mean_squared_error: 0.5484 - val_loss: 0.3689 - val_root_mean_squared_error: 0.6074\n",
      "Epoch 4/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2884 - root_mean_squared_error: 0.5370 - val_loss: 0.3521 - val_root_mean_squared_error: 0.5934\n",
      "Epoch 5/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2833 - root_mean_squared_error: 0.5323 - val_loss: 0.3476 - val_root_mean_squared_error: 0.5896\n",
      "Epoch 6/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2742 - root_mean_squared_error: 0.5236 - val_loss: 0.3793 - val_root_mean_squared_error: 0.6159\n",
      "Epoch 7/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2803 - root_mean_squared_error: 0.5295 - val_loss: 0.3346 - val_root_mean_squared_error: 0.5785\n",
      "Epoch 8/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2768 - root_mean_squared_error: 0.5261 - val_loss: 0.3373 - val_root_mean_squared_error: 0.5808\n",
      "Epoch 9/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2662 - root_mean_squared_error: 0.5160 - val_loss: 0.3421 - val_root_mean_squared_error: 0.5849\n",
      "Epoch 10/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2642 - root_mean_squared_error: 0.5140 - val_loss: 0.3400 - val_root_mean_squared_error: 0.5831\n",
      "Epoch 11/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2634 - root_mean_squared_error: 0.5132 - val_loss: 0.3410 - val_root_mean_squared_error: 0.5839\n",
      "Epoch 12/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2555 - root_mean_squared_error: 0.5054 - val_loss: 0.3158 - val_root_mean_squared_error: 0.5620\n",
      "Epoch 13/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2532 - root_mean_squared_error: 0.5032 - val_loss: 0.3228 - val_root_mean_squared_error: 0.5682\n",
      "Epoch 14/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2486 - root_mean_squared_error: 0.4986 - val_loss: 0.3385 - val_root_mean_squared_error: 0.5818\n",
      "Epoch 15/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2497 - root_mean_squared_error: 0.4997 - val_loss: 0.3080 - val_root_mean_squared_error: 0.5550\n",
      "Epoch 16/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2457 - root_mean_squared_error: 0.4957 - val_loss: 0.3180 - val_root_mean_squared_error: 0.5639\n",
      "Epoch 17/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2479 - root_mean_squared_error: 0.4979 - val_loss: 0.3043 - val_root_mean_squared_error: 0.5516\n",
      "Epoch 18/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2486 - root_mean_squared_error: 0.4986 - val_loss: 0.3415 - val_root_mean_squared_error: 0.5844\n",
      "Epoch 19/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2437 - root_mean_squared_error: 0.4937 - val_loss: 0.3017 - val_root_mean_squared_error: 0.5493\n",
      "Epoch 20/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2505 - root_mean_squared_error: 0.5005 - val_loss: 0.3291 - val_root_mean_squared_error: 0.5737\n",
      "Epoch 21/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2469 - root_mean_squared_error: 0.4969 - val_loss: 0.3078 - val_root_mean_squared_error: 0.5548\n",
      "Epoch 22/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2431 - root_mean_squared_error: 0.4930 - val_loss: 0.3120 - val_root_mean_squared_error: 0.5586\n",
      "Epoch 23/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2484 - root_mean_squared_error: 0.4984 - val_loss: 0.3212 - val_root_mean_squared_error: 0.5668\n",
      "Epoch 24/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2463 - root_mean_squared_error: 0.4963 - val_loss: 0.3149 - val_root_mean_squared_error: 0.5611\n",
      "54/54 [==============================] - 1s 5ms/step\n",
      "20/20 [==============================] - 0s 5ms/step\n",
      "Train Score: 5.81 RMSE\n",
      "Test Score: 6.46 RMSE\n",
      "Model: \"model_61\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_62 (InputLayer)       [(None, 80, 1)]           0         \n",
      "                                                                 \n",
      " lstm_122 (LSTM)             (None, 80, 60)            14880     \n",
      "                                                                 \n",
      " lstm_123 (LSTM)             (None, 60)                29040     \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 1)                 61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,981\n",
      "Trainable params: 43,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "54/54 [==============================] - 4s 32ms/step - loss: 0.4059 - root_mean_squared_error: 0.6371 - val_loss: 0.4257 - val_root_mean_squared_error: 0.6524\n",
      "Epoch 2/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.3146 - root_mean_squared_error: 0.5609 - val_loss: 0.3920 - val_root_mean_squared_error: 0.6261\n",
      "Epoch 3/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2981 - root_mean_squared_error: 0.5460 - val_loss: 0.3645 - val_root_mean_squared_error: 0.6037\n",
      "Epoch 4/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2892 - root_mean_squared_error: 0.5378 - val_loss: 0.3496 - val_root_mean_squared_error: 0.5913\n",
      "Epoch 5/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2782 - root_mean_squared_error: 0.5274 - val_loss: 0.3521 - val_root_mean_squared_error: 0.5934\n",
      "Epoch 6/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2797 - root_mean_squared_error: 0.5288 - val_loss: 0.3584 - val_root_mean_squared_error: 0.5987\n",
      "Epoch 7/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2750 - root_mean_squared_error: 0.5244 - val_loss: 0.3378 - val_root_mean_squared_error: 0.5812\n",
      "Epoch 8/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2678 - root_mean_squared_error: 0.5175 - val_loss: 0.3258 - val_root_mean_squared_error: 0.5708\n",
      "Epoch 9/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2680 - root_mean_squared_error: 0.5177 - val_loss: 0.3340 - val_root_mean_squared_error: 0.5779\n",
      "Epoch 10/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2605 - root_mean_squared_error: 0.5104 - val_loss: 0.3427 - val_root_mean_squared_error: 0.5854\n",
      "Epoch 11/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2645 - root_mean_squared_error: 0.5143 - val_loss: 0.3297 - val_root_mean_squared_error: 0.5742\n",
      "Epoch 12/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2556 - root_mean_squared_error: 0.5056 - val_loss: 0.3407 - val_root_mean_squared_error: 0.5837\n",
      "Epoch 13/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2536 - root_mean_squared_error: 0.5036 - val_loss: 0.3460 - val_root_mean_squared_error: 0.5882\n",
      "54/54 [==============================] - 1s 5ms/step\n",
      "20/20 [==============================] - 0s 6ms/step\n",
      "Train Score: 6.10 RMSE\n",
      "Test Score: 6.62 RMSE\n",
      "Model: \"model_62\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_63 (InputLayer)       [(None, 80, 1)]           0         \n",
      "                                                                 \n",
      " lstm_124 (LSTM)             (None, 80, 60)            14880     \n",
      "                                                                 \n",
      " lstm_125 (LSTM)             (None, 60)                29040     \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 1)                 61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,981\n",
      "Trainable params: 43,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "54/54 [==============================] - 4s 28ms/step - loss: 0.4065 - root_mean_squared_error: 0.6375 - val_loss: 0.4232 - val_root_mean_squared_error: 0.6506\n",
      "Epoch 2/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.3129 - root_mean_squared_error: 0.5594 - val_loss: 0.3876 - val_root_mean_squared_error: 0.6226\n",
      "Epoch 3/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2972 - root_mean_squared_error: 0.5451 - val_loss: 0.3691 - val_root_mean_squared_error: 0.6075\n",
      "Epoch 4/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2807 - root_mean_squared_error: 0.5298 - val_loss: 0.3452 - val_root_mean_squared_error: 0.5876\n",
      "Epoch 5/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2725 - root_mean_squared_error: 0.5220 - val_loss: 0.3409 - val_root_mean_squared_error: 0.5838\n",
      "Epoch 6/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2608 - root_mean_squared_error: 0.5106 - val_loss: 0.3311 - val_root_mean_squared_error: 0.5754\n",
      "Epoch 7/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2638 - root_mean_squared_error: 0.5136 - val_loss: 0.3208 - val_root_mean_squared_error: 0.5664\n",
      "Epoch 8/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2608 - root_mean_squared_error: 0.5106 - val_loss: 0.3209 - val_root_mean_squared_error: 0.5665\n",
      "Epoch 9/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2565 - root_mean_squared_error: 0.5064 - val_loss: 0.3189 - val_root_mean_squared_error: 0.5648\n",
      "Epoch 10/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2555 - root_mean_squared_error: 0.5054 - val_loss: 0.3172 - val_root_mean_squared_error: 0.5632\n",
      "Epoch 11/500\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.2510 - root_mean_squared_error: 0.5010 - val_loss: 0.3348 - val_root_mean_squared_error: 0.5786\n",
      "Epoch 12/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2524 - root_mean_squared_error: 0.5024 - val_loss: 0.3060 - val_root_mean_squared_error: 0.5532\n",
      "Epoch 13/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2526 - root_mean_squared_error: 0.5026 - val_loss: 0.3183 - val_root_mean_squared_error: 0.5642\n",
      "Epoch 14/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2497 - root_mean_squared_error: 0.4997 - val_loss: 0.3147 - val_root_mean_squared_error: 0.5610\n",
      "Epoch 15/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2684 - root_mean_squared_error: 0.5181 - val_loss: 0.3362 - val_root_mean_squared_error: 0.5798\n",
      "Epoch 16/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2529 - root_mean_squared_error: 0.5029 - val_loss: 0.3191 - val_root_mean_squared_error: 0.5649\n",
      "Epoch 17/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2486 - root_mean_squared_error: 0.4986 - val_loss: 0.3239 - val_root_mean_squared_error: 0.5691\n",
      "54/54 [==============================] - 1s 5ms/step\n",
      "20/20 [==============================] - 0s 5ms/step\n",
      "Train Score: 5.91 RMSE\n",
      "Test Score: 6.53 RMSE\n",
      "Model: \"model_63\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_64 (InputLayer)       [(None, 80, 1)]           0         \n",
      "                                                                 \n",
      " lstm_126 (LSTM)             (None, 80, 60)            14880     \n",
      "                                                                 \n",
      " lstm_127 (LSTM)             (None, 60)                29040     \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 1)                 61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,981\n",
      "Trainable params: 43,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "54/54 [==============================] - 4s 27ms/step - loss: 0.4052 - root_mean_squared_error: 0.6366 - val_loss: 0.4507 - val_root_mean_squared_error: 0.6713\n",
      "Epoch 2/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.3159 - root_mean_squared_error: 0.5621 - val_loss: 0.3847 - val_root_mean_squared_error: 0.6202\n",
      "Epoch 3/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2964 - root_mean_squared_error: 0.5444 - val_loss: 0.3722 - val_root_mean_squared_error: 0.6101\n",
      "Epoch 4/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2863 - root_mean_squared_error: 0.5351 - val_loss: 0.3582 - val_root_mean_squared_error: 0.5985\n",
      "Epoch 5/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2776 - root_mean_squared_error: 0.5269 - val_loss: 0.3359 - val_root_mean_squared_error: 0.5796\n",
      "Epoch 6/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2749 - root_mean_squared_error: 0.5243 - val_loss: 0.3245 - val_root_mean_squared_error: 0.5696\n",
      "Epoch 7/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2663 - root_mean_squared_error: 0.5160 - val_loss: 0.3289 - val_root_mean_squared_error: 0.5735\n",
      "Epoch 8/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2617 - root_mean_squared_error: 0.5115 - val_loss: 0.3640 - val_root_mean_squared_error: 0.6033\n",
      "Epoch 9/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2735 - root_mean_squared_error: 0.5230 - val_loss: 0.3335 - val_root_mean_squared_error: 0.5775\n",
      "Epoch 10/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2641 - root_mean_squared_error: 0.5139 - val_loss: 0.3235 - val_root_mean_squared_error: 0.5687\n",
      "Epoch 11/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2580 - root_mean_squared_error: 0.5080 - val_loss: 0.3375 - val_root_mean_squared_error: 0.5810\n",
      "Epoch 12/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2569 - root_mean_squared_error: 0.5069 - val_loss: 0.3259 - val_root_mean_squared_error: 0.5709\n",
      "Epoch 13/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2579 - root_mean_squared_error: 0.5078 - val_loss: 0.3112 - val_root_mean_squared_error: 0.5578\n",
      "Epoch 14/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2542 - root_mean_squared_error: 0.5042 - val_loss: 0.3122 - val_root_mean_squared_error: 0.5588\n",
      "Epoch 15/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2480 - root_mean_squared_error: 0.4980 - val_loss: 0.3041 - val_root_mean_squared_error: 0.5515\n",
      "Epoch 16/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2492 - root_mean_squared_error: 0.4992 - val_loss: 0.3040 - val_root_mean_squared_error: 0.5514\n",
      "Epoch 17/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2505 - root_mean_squared_error: 0.5005 - val_loss: 0.3148 - val_root_mean_squared_error: 0.5611\n",
      "Epoch 18/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2461 - root_mean_squared_error: 0.4961 - val_loss: 0.3106 - val_root_mean_squared_error: 0.5574\n",
      "Epoch 19/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2462 - root_mean_squared_error: 0.4962 - val_loss: 0.3107 - val_root_mean_squared_error: 0.5574\n",
      "Epoch 20/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2464 - root_mean_squared_error: 0.4964 - val_loss: 0.3030 - val_root_mean_squared_error: 0.5504\n",
      "Epoch 21/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2411 - root_mean_squared_error: 0.4910 - val_loss: 0.2981 - val_root_mean_squared_error: 0.5460\n",
      "Epoch 22/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2377 - root_mean_squared_error: 0.4875 - val_loss: 0.3097 - val_root_mean_squared_error: 0.5565\n",
      "Epoch 23/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2457 - root_mean_squared_error: 0.4957 - val_loss: 0.3184 - val_root_mean_squared_error: 0.5643\n",
      "Epoch 24/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2391 - root_mean_squared_error: 0.4890 - val_loss: 0.2948 - val_root_mean_squared_error: 0.5430\n",
      "Epoch 25/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2437 - root_mean_squared_error: 0.4937 - val_loss: 0.3532 - val_root_mean_squared_error: 0.5943\n",
      "Epoch 26/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2377 - root_mean_squared_error: 0.4876 - val_loss: 0.2873 - val_root_mean_squared_error: 0.5360\n",
      "Epoch 27/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2369 - root_mean_squared_error: 0.4868 - val_loss: 0.3409 - val_root_mean_squared_error: 0.5838\n",
      "Epoch 28/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2450 - root_mean_squared_error: 0.4950 - val_loss: 0.3123 - val_root_mean_squared_error: 0.5589\n",
      "Epoch 29/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2359 - root_mean_squared_error: 0.4857 - val_loss: 0.3138 - val_root_mean_squared_error: 0.5602\n",
      "Epoch 30/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2357 - root_mean_squared_error: 0.4855 - val_loss: 0.3038 - val_root_mean_squared_error: 0.5512\n",
      "Epoch 31/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2312 - root_mean_squared_error: 0.4808 - val_loss: 0.2861 - val_root_mean_squared_error: 0.5349\n",
      "Epoch 32/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2367 - root_mean_squared_error: 0.4865 - val_loss: 0.2991 - val_root_mean_squared_error: 0.5469\n",
      "Epoch 33/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2322 - root_mean_squared_error: 0.4819 - val_loss: 0.2906 - val_root_mean_squared_error: 0.5390\n",
      "Epoch 34/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2329 - root_mean_squared_error: 0.4826 - val_loss: 0.2990 - val_root_mean_squared_error: 0.5468\n",
      "Epoch 35/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2307 - root_mean_squared_error: 0.4803 - val_loss: 0.3047 - val_root_mean_squared_error: 0.5520\n",
      "Epoch 36/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2275 - root_mean_squared_error: 0.4770 - val_loss: 0.2951 - val_root_mean_squared_error: 0.5433\n",
      "54/54 [==============================] - 1s 5ms/step\n",
      "20/20 [==============================] - 0s 5ms/step\n",
      "Train Score: 5.62 RMSE\n",
      "Test Score: 6.46 RMSE\n",
      "Model: \"model_64\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_65 (InputLayer)       [(None, 80, 1)]           0         \n",
      "                                                                 \n",
      " lstm_128 (LSTM)             (None, 80, 60)            14880     \n",
      "                                                                 \n",
      " lstm_129 (LSTM)             (None, 60)                29040     \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 1)                 61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,981\n",
      "Trainable params: 43,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "54/54 [==============================] - 4s 29ms/step - loss: 0.4125 - root_mean_squared_error: 0.6423 - val_loss: 0.4205 - val_root_mean_squared_error: 0.6484\n",
      "Epoch 2/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.3166 - root_mean_squared_error: 0.5626 - val_loss: 0.3901 - val_root_mean_squared_error: 0.6246\n",
      "Epoch 3/500\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 0.2965 - root_mean_squared_error: 0.5446 - val_loss: 0.3730 - val_root_mean_squared_error: 0.6107\n",
      "Epoch 4/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2868 - root_mean_squared_error: 0.5355 - val_loss: 0.3729 - val_root_mean_squared_error: 0.6106\n",
      "Epoch 5/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2821 - root_mean_squared_error: 0.5311 - val_loss: 0.3485 - val_root_mean_squared_error: 0.5904\n",
      "Epoch 6/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2790 - root_mean_squared_error: 0.5282 - val_loss: 0.3417 - val_root_mean_squared_error: 0.5845\n",
      "Epoch 7/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2687 - root_mean_squared_error: 0.5184 - val_loss: 0.3413 - val_root_mean_squared_error: 0.5842\n",
      "Epoch 8/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2659 - root_mean_squared_error: 0.5156 - val_loss: 0.3414 - val_root_mean_squared_error: 0.5843\n",
      "Epoch 9/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2761 - root_mean_squared_error: 0.5254 - val_loss: 0.3888 - val_root_mean_squared_error: 0.6236\n",
      "Epoch 10/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2682 - root_mean_squared_error: 0.5179 - val_loss: 0.3273 - val_root_mean_squared_error: 0.5721\n",
      "Epoch 11/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2567 - root_mean_squared_error: 0.5067 - val_loss: 0.3250 - val_root_mean_squared_error: 0.5701\n",
      "Epoch 12/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2551 - root_mean_squared_error: 0.5051 - val_loss: 0.3120 - val_root_mean_squared_error: 0.5585\n",
      "Epoch 13/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2550 - root_mean_squared_error: 0.5050 - val_loss: 0.3227 - val_root_mean_squared_error: 0.5680\n",
      "Epoch 14/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2532 - root_mean_squared_error: 0.5032 - val_loss: 0.3224 - val_root_mean_squared_error: 0.5678\n",
      "Epoch 15/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2479 - root_mean_squared_error: 0.4979 - val_loss: 0.3345 - val_root_mean_squared_error: 0.5784\n",
      "Epoch 16/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2532 - root_mean_squared_error: 0.5032 - val_loss: 0.3179 - val_root_mean_squared_error: 0.5638\n",
      "Epoch 17/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2473 - root_mean_squared_error: 0.4973 - val_loss: 0.3244 - val_root_mean_squared_error: 0.5696\n",
      "54/54 [==============================] - 1s 5ms/step\n",
      "20/20 [==============================] - 0s 6ms/step\n",
      "Train Score: 5.90 RMSE\n",
      "Test Score: 6.61 RMSE\n",
      "Model: \"model_65\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_66 (InputLayer)       [(None, 80, 1)]           0         \n",
      "                                                                 \n",
      " lstm_130 (LSTM)             (None, 80, 60)            14880     \n",
      "                                                                 \n",
      " lstm_131 (LSTM)             (None, 60)                29040     \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 1)                 61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,981\n",
      "Trainable params: 43,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "54/54 [==============================] - 4s 28ms/step - loss: 0.4070 - root_mean_squared_error: 0.6379 - val_loss: 0.4182 - val_root_mean_squared_error: 0.6467\n",
      "Epoch 2/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.3103 - root_mean_squared_error: 0.5570 - val_loss: 0.3862 - val_root_mean_squared_error: 0.6214\n",
      "Epoch 3/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2969 - root_mean_squared_error: 0.5449 - val_loss: 0.3664 - val_root_mean_squared_error: 0.6053\n",
      "Epoch 4/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2838 - root_mean_squared_error: 0.5327 - val_loss: 0.3747 - val_root_mean_squared_error: 0.6121\n",
      "Epoch 5/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2838 - root_mean_squared_error: 0.5328 - val_loss: 0.3438 - val_root_mean_squared_error: 0.5864\n",
      "Epoch 6/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2777 - root_mean_squared_error: 0.5270 - val_loss: 0.3458 - val_root_mean_squared_error: 0.5880\n",
      "Epoch 7/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2684 - root_mean_squared_error: 0.5181 - val_loss: 0.3342 - val_root_mean_squared_error: 0.5781\n",
      "Epoch 8/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2680 - root_mean_squared_error: 0.5176 - val_loss: 0.3375 - val_root_mean_squared_error: 0.5809\n",
      "Epoch 9/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2620 - root_mean_squared_error: 0.5119 - val_loss: 0.3319 - val_root_mean_squared_error: 0.5761\n",
      "Epoch 10/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2539 - root_mean_squared_error: 0.5038 - val_loss: 0.3106 - val_root_mean_squared_error: 0.5573\n",
      "Epoch 11/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2571 - root_mean_squared_error: 0.5071 - val_loss: 0.3210 - val_root_mean_squared_error: 0.5665\n",
      "Epoch 12/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2553 - root_mean_squared_error: 0.5052 - val_loss: 0.3284 - val_root_mean_squared_error: 0.5730\n",
      "Epoch 13/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2507 - root_mean_squared_error: 0.5007 - val_loss: 0.3087 - val_root_mean_squared_error: 0.5556\n",
      "Epoch 14/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2500 - root_mean_squared_error: 0.5000 - val_loss: 0.3138 - val_root_mean_squared_error: 0.5602\n",
      "Epoch 15/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2521 - root_mean_squared_error: 0.5021 - val_loss: 0.3242 - val_root_mean_squared_error: 0.5694\n",
      "Epoch 16/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2486 - root_mean_squared_error: 0.4986 - val_loss: 0.3134 - val_root_mean_squared_error: 0.5598\n",
      "Epoch 17/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2437 - root_mean_squared_error: 0.4937 - val_loss: 0.3026 - val_root_mean_squared_error: 0.5501\n",
      "Epoch 18/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2517 - root_mean_squared_error: 0.5017 - val_loss: 0.3152 - val_root_mean_squared_error: 0.5614\n",
      "Epoch 19/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2486 - root_mean_squared_error: 0.4986 - val_loss: 0.3208 - val_root_mean_squared_error: 0.5664\n",
      "Epoch 20/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2408 - root_mean_squared_error: 0.4908 - val_loss: 0.3037 - val_root_mean_squared_error: 0.5511\n",
      "Epoch 21/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2419 - root_mean_squared_error: 0.4918 - val_loss: 0.3196 - val_root_mean_squared_error: 0.5653\n",
      "Epoch 22/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2417 - root_mean_squared_error: 0.4917 - val_loss: 0.3235 - val_root_mean_squared_error: 0.5688\n",
      "54/54 [==============================] - 1s 6ms/step\n",
      "20/20 [==============================] - 0s 6ms/step\n",
      "Train Score: 5.81 RMSE\n",
      "Test Score: 6.51 RMSE\n",
      "Model: \"model_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_67 (InputLayer)       [(None, 80, 1)]           0         \n",
      "                                                                 \n",
      " lstm_132 (LSTM)             (None, 80, 60)            14880     \n",
      "                                                                 \n",
      " lstm_133 (LSTM)             (None, 60)                29040     \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 1)                 61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,981\n",
      "Trainable params: 43,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "54/54 [==============================] - 4s 29ms/step - loss: 0.4188 - root_mean_squared_error: 0.6471 - val_loss: 0.4334 - val_root_mean_squared_error: 0.6584\n",
      "Epoch 2/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.3167 - root_mean_squared_error: 0.5627 - val_loss: 0.3919 - val_root_mean_squared_error: 0.6260\n",
      "Epoch 3/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.3033 - root_mean_squared_error: 0.5508 - val_loss: 0.3803 - val_root_mean_squared_error: 0.6167\n",
      "Epoch 4/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2930 - root_mean_squared_error: 0.5413 - val_loss: 0.3708 - val_root_mean_squared_error: 0.6089\n",
      "Epoch 5/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2773 - root_mean_squared_error: 0.5266 - val_loss: 0.3786 - val_root_mean_squared_error: 0.6153\n",
      "Epoch 6/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2930 - root_mean_squared_error: 0.5413 - val_loss: 0.3923 - val_root_mean_squared_error: 0.6263\n",
      "Epoch 7/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2770 - root_mean_squared_error: 0.5263 - val_loss: 0.3533 - val_root_mean_squared_error: 0.5944\n",
      "Epoch 8/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2752 - root_mean_squared_error: 0.5246 - val_loss: 0.3376 - val_root_mean_squared_error: 0.5810\n",
      "Epoch 9/500\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.2700 - root_mean_squared_error: 0.5196 - val_loss: 0.3339 - val_root_mean_squared_error: 0.5778\n",
      "Epoch 10/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2628 - root_mean_squared_error: 0.5126 - val_loss: 0.3302 - val_root_mean_squared_error: 0.5746\n",
      "Epoch 11/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2569 - root_mean_squared_error: 0.5068 - val_loss: 0.3292 - val_root_mean_squared_error: 0.5738\n",
      "Epoch 12/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2592 - root_mean_squared_error: 0.5091 - val_loss: 0.3243 - val_root_mean_squared_error: 0.5694\n",
      "Epoch 13/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2593 - root_mean_squared_error: 0.5093 - val_loss: 0.3159 - val_root_mean_squared_error: 0.5621\n",
      "Epoch 14/500\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.2574 - root_mean_squared_error: 0.5074 - val_loss: 0.3176 - val_root_mean_squared_error: 0.5636\n",
      "Epoch 15/500\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.2561 - root_mean_squared_error: 0.5060 - val_loss: 0.3059 - val_root_mean_squared_error: 0.5531\n",
      "Epoch 16/500\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.2547 - root_mean_squared_error: 0.5046 - val_loss: 0.3496 - val_root_mean_squared_error: 0.5913\n",
      "Epoch 17/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2497 - root_mean_squared_error: 0.4997 - val_loss: 0.3270 - val_root_mean_squared_error: 0.5718\n",
      "Epoch 18/500\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.2484 - root_mean_squared_error: 0.4984 - val_loss: 0.3543 - val_root_mean_squared_error: 0.5952\n",
      "Epoch 19/500\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.2478 - root_mean_squared_error: 0.4978 - val_loss: 0.3149 - val_root_mean_squared_error: 0.5612\n",
      "Epoch 20/500\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.2454 - root_mean_squared_error: 0.4953 - val_loss: 0.3176 - val_root_mean_squared_error: 0.5636\n",
      "54/54 [==============================] - 1s 6ms/step\n",
      "20/20 [==============================] - 0s 6ms/step\n",
      "Train Score: 5.80 RMSE\n",
      "Test Score: 6.52 RMSE\n",
      "Model: \"model_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_68 (InputLayer)       [(None, 80, 1)]           0         \n",
      "                                                                 \n",
      " lstm_134 (LSTM)             (None, 80, 60)            14880     \n",
      "                                                                 \n",
      " lstm_135 (LSTM)             (None, 60)                29040     \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 1)                 61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,981\n",
      "Trainable params: 43,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "54/54 [==============================] - 4s 37ms/step - loss: 0.4306 - root_mean_squared_error: 0.6562 - val_loss: 0.4293 - val_root_mean_squared_error: 0.6552\n",
      "Epoch 2/500\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.3189 - root_mean_squared_error: 0.5647 - val_loss: 0.3890 - val_root_mean_squared_error: 0.6237\n",
      "Epoch 3/500\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.2973 - root_mean_squared_error: 0.5452 - val_loss: 0.3722 - val_root_mean_squared_error: 0.6101\n",
      "Epoch 4/500\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.2901 - root_mean_squared_error: 0.5386 - val_loss: 0.3601 - val_root_mean_squared_error: 0.6001\n",
      "Epoch 5/500\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 0.2809 - root_mean_squared_error: 0.5300 - val_loss: 0.3570 - val_root_mean_squared_error: 0.5975\n",
      "Epoch 6/500\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 0.2776 - root_mean_squared_error: 0.5269 - val_loss: 0.3377 - val_root_mean_squared_error: 0.5812\n",
      "Epoch 7/500\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 0.2726 - root_mean_squared_error: 0.5221 - val_loss: 0.3472 - val_root_mean_squared_error: 0.5892\n",
      "Epoch 8/500\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.2660 - root_mean_squared_error: 0.5158 - val_loss: 0.3195 - val_root_mean_squared_error: 0.5653\n",
      "Epoch 9/500\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.2632 - root_mean_squared_error: 0.5130 - val_loss: 0.3295 - val_root_mean_squared_error: 0.5740\n",
      "Epoch 10/500\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.2607 - root_mean_squared_error: 0.5106 - val_loss: 0.3344 - val_root_mean_squared_error: 0.5783\n",
      "Epoch 11/500\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.2569 - root_mean_squared_error: 0.5069 - val_loss: 0.3417 - val_root_mean_squared_error: 0.5846\n",
      "Epoch 12/500\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.2533 - root_mean_squared_error: 0.5033 - val_loss: 0.3104 - val_root_mean_squared_error: 0.5572\n",
      "Epoch 13/500\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.2487 - root_mean_squared_error: 0.4987 - val_loss: 0.3197 - val_root_mean_squared_error: 0.5654\n",
      "Epoch 14/500\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.2566 - root_mean_squared_error: 0.5065 - val_loss: 0.3123 - val_root_mean_squared_error: 0.5588\n",
      "Epoch 15/500\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.2443 - root_mean_squared_error: 0.4943 - val_loss: 0.3272 - val_root_mean_squared_error: 0.5720\n",
      "Epoch 16/500\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 0.2484 - root_mean_squared_error: 0.4984 - val_loss: 0.3181 - val_root_mean_squared_error: 0.5640\n",
      "Epoch 17/500\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 0.2521 - root_mean_squared_error: 0.5021 - val_loss: 0.3146 - val_root_mean_squared_error: 0.5609\n",
      "54/54 [==============================] - 1s 6ms/step\n",
      "20/20 [==============================] - 0s 6ms/step\n",
      "Train Score: 5.83 RMSE\n",
      "Test Score: 6.47 RMSE\n",
      "Run 1:\n",
      "  Train Score: 5.75 RMSE\n",
      "  Test Score: 6.46 RMSE\n",
      "Run 2:\n",
      "  Train Score: 5.82 RMSE\n",
      "  Test Score: 6.57 RMSE\n",
      "Run 3:\n",
      "  Train Score: 5.81 RMSE\n",
      "  Test Score: 6.46 RMSE\n",
      "Run 4:\n",
      "  Train Score: 6.10 RMSE\n",
      "  Test Score: 6.62 RMSE\n",
      "Run 5:\n",
      "  Train Score: 5.91 RMSE\n",
      "  Test Score: 6.53 RMSE\n",
      "Run 6:\n",
      "  Train Score: 5.62 RMSE\n",
      "  Test Score: 6.46 RMSE\n",
      "Run 7:\n",
      "  Train Score: 5.90 RMSE\n",
      "  Test Score: 6.61 RMSE\n",
      "Run 8:\n",
      "  Train Score: 5.81 RMSE\n",
      "  Test Score: 6.51 RMSE\n",
      "Run 9:\n",
      "  Train Score: 5.80 RMSE\n",
      "  Test Score: 6.52 RMSE\n",
      "Run 10:\n",
      "  Train Score: 5.83 RMSE\n",
      "  Test Score: 6.47 RMSE\n"
     ]
    }
   ],
   "source": [
    "rmses = []\n",
    "val_rmses = []\n",
    "trainscores = []\n",
    "testscores = []\n",
    "runs = 10\n",
    "epochs = 500\n",
    "\n",
    "\n",
    "for i in range(runs):\n",
    "    #Add params to do optimizing at the top\n",
    "    # input_dim = 1\n",
    "    input_dim = data.shape[1]\n",
    "    units = 60\n",
    "    # output_size = 1\n",
    "    output_size = y_train.shape[1]\n",
    "\n",
    "    input = keras.Input((look_back, input_dim))\n",
    "    #return sequences is necessary for sequential LSTM layers\n",
    "    lstm1 = LSTM(units, return_sequences=True)(input)\n",
    "    lstm2 = LSTM(units)(lstm1)\n",
    "    out = Dense(output_size)(lstm2)\n",
    "    model = keras.models.Model(inputs=input, outputs=out)\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(\n",
    "        loss=MeanSquaredError(),\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        metrics=[keras.metrics.RootMeanSquaredError()],\n",
    "    )\n",
    "\n",
    "    cback = [keras.callbacks.EarlyStopping(patience=5)]\n",
    "    # if runs == 1:\n",
    "    #     cback = [keras.callbacks.EarlyStopping(patience=10)]\n",
    "\n",
    "\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        epochs=epochs,\n",
    "        #makes the training stop early if it notices no improvements on the validation set 10 times in a row, to prevent overfitting\n",
    "        callbacks=cback,\n",
    "    )\n",
    "\n",
    "    # save data to calculate the learning curve\n",
    "    rmses.append(history.history['root_mean_squared_error'])\n",
    "    val_rmses.append(history.history['val_root_mean_squared_error'])\n",
    "\n",
    "    # make predictions\n",
    "    trainPredict = model.predict(x_train)\n",
    "    testPredict = model.predict(x_test)\n",
    "    # invert predictions\n",
    "    trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    trainY = scaler.inverse_transform(y_train)\n",
    "    testPredict = scaler.inverse_transform(testPredict)\n",
    "    testY = scaler.inverse_transform(y_test)\n",
    "    # calculate root mean squared error\n",
    "    trainScore = np.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "    print(f'Train Score: {trainScore:.2f} RMSE')\n",
    "    testScore = np.sqrt(mean_squared_error(testY, testPredict))\n",
    "    print(f'Test Score: {testScore:.2f} RMSE')\n",
    "    trainscores.append(trainScore)\n",
    "    testscores.append(testScore)\n",
    "\n",
    "for i in range(runs):\n",
    "    print(f'Run {i+1}:')\n",
    "    print(f'  Train Score: {trainscores[i]:.2f} RMSE')\n",
    "    print(f'  Test Score: {testscores[i]:.2f} RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-09T15:28:02.351253300Z",
     "start_time": "2023-06-09T15:28:02.302085600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscores: [5.750163067039128, 5.823281466985095, 5.808611991713464, 6.095367730070231, 5.90805554537215, 5.623101054294955, 5.901341613796622, 5.813693011400218, 5.797063243798349, 5.834219990716134]\n",
      "testscores: [6.4555772829633895, 6.569485446647466, 6.45978205721166, 6.622722594013811, 6.531599712040477, 6.458144069506753, 6.611279765145696, 6.5062721229630744, 6.524153557037169, 6.469869516070491]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (10,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[160], line 7\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrainscores: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(trainscores))\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtestscores: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(testscores))\n\u001B[1;32m----> 7\u001B[0m rmses \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatrix\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrmses\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m val_rmses \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmatrix(val_rmses)\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(rmses\u001B[38;5;241m.\u001B[39mshape)\n",
      "File \u001B[1;32m~\\Miniconda3\\envs\\tf\\lib\\site-packages\\numpy\\matrixlib\\defmatrix.py:145\u001B[0m, in \u001B[0;36mmatrix.__new__\u001B[1;34m(subtype, data, dtype, copy)\u001B[0m\n\u001B[0;32m    142\u001B[0m     data \u001B[38;5;241m=\u001B[39m _convert_from_string(data)\n\u001B[0;32m    144\u001B[0m \u001B[38;5;66;03m# now convert data to an array\u001B[39;00m\n\u001B[1;32m--> 145\u001B[0m arr \u001B[38;5;241m=\u001B[39m \u001B[43mN\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    146\u001B[0m ndim \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mndim\n\u001B[0;32m    147\u001B[0m shape \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mshape\n",
      "\u001B[1;31mValueError\u001B[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (10,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# rmses = scaler.inverse_transform(rmses)\n",
    "# val_rmses = scaler.inverse_transform(val_rmses)\n",
    "\n",
    "print(\"trainscores: \" + str(trainscores))\n",
    "print(\"testscores: \" + str(testscores))\n",
    "\n",
    "rmses = np.matrix(rmses)\n",
    "val_rmses = np.matrix(val_rmses)\n",
    "\n",
    "print(rmses.shape)\n",
    "\n",
    "rmse_avg = np.mean(rmses, axis=0).transpose()\n",
    "val_rmse_avg = np.mean(val_rmses, axis=0).transpose()\n",
    "\n",
    "print(rmse_avg.shape)\n",
    "\n",
    "rmse_std = np.std(rmses, axis=0).transpose()\n",
    "val_rmse_std = np.std(val_rmses, axis=0).transpose()\n",
    "\n",
    "sigma = 1\n",
    "skip = 3\n",
    "\n",
    "rmse_std_high = rmse_avg + rmse_std * sigma\n",
    "rmse_std_low = rmse_avg - rmse_std * sigma\n",
    "val_rmse_std_high = val_rmse_avg + val_rmse_std * sigma\n",
    "val_rmse_std_low = val_rmse_avg - val_rmse_std * sigma\n",
    "\n",
    "\n",
    "plt.plot(rmse_avg[skip:], label='train', color='orange')\n",
    "plt.plot(val_rmse_avg[skip:], label='validation', color='green')\n",
    "plt.plot(rmse_std_high[skip:], label='train std', linestyle='dashed', color='orange')\n",
    "plt.plot(rmse_std_low[skip:], label='_nolegend_', linestyle='dashed', color='orange')\n",
    "plt.plot(val_rmse_std_high[skip:], label='validation std', linestyle='dashed', color='green')\n",
    "plt.plot(val_rmse_std_low[skip:], label='_nolegend_', linestyle='dashed', color='green')\n",
    "plt.title(\"learning curve\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss (RMSE)')\n",
    "plt.legend(['train', 'validation', 'train_std', 'validation_std'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean([8.14,7.87,7.86,7.96,7.93]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
